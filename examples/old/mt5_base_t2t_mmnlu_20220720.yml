run_name: &run_name mt5_base_t2t_mmnlu_20220720
max_length: &max_length 512

model:
  type: mt5 for conditional generation
  checkpoint: /PATH/TO/YOUR/MODEL

tokenizer:
  type: mt5
  tok_args:
    vocab_file: /PATH/TO/TOKENIZER
    max_len: *max_length

collator:
  type: massive text to text intent class slot fill
  args:
    max_length: *max_length
    padding: longest
    t2t_args:
      input_prompt: "Annotate: " # set to false for no prompt
      use_output_descrip: false
      intent_first: false
      slots_mixed: false
      toks_in_output: false
      sentinels: false
      inside_format: slot_name
      outside_label: Other

test:
  trainer: massive s2s
  test_dataset: /PATH/TO/hf-mmnlu-eval/hf-mmnlu-eval.mmnlu22
  #test_shorten_to: 50
  intent_labels: /PATH/TO/hf-mmnlu-eval/hf-mmnlu-eval.intents
  slot_labels: /PATH/TO/hf-mmnlu-eval/hf-mmnlu-eval.slots
  predictions_file: /PATH/TO/preds.jsonl
  slots_labels_ignore:
    - Other
  trainer_args:
    output_dir: /PATH/TO/mt5_base_t2t_mmnlu_20220720/
    per_device_eval_batch_size: 64
    eval_accumulation_steps: 1
    remove_unused_columns: false
    log_level: info
    logging_strategy: no
    predict_with_generate: true
    generation_max_length: *max_length
    generation_num_beams: 2
    disable_tqdm: false
